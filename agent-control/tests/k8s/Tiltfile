# -*- mode: Python -*-
# This Tiltfile is used by the integration tests to setup the environment.

update_settings( k8s_upsert_timeout_secs = 150)
ci_settings(readiness_timeout = '10m')
load('ext://helm_resource', 'helm_repo','helm_resource')
load('ext://git_resource', 'git_checkout')
load('ext://deployment', 'job_create')
load('ext://helm_remote', 'helm_remote')

#### Install Flux needed for some integration tests
helm_repo(
  'newrelic',
  'https://helm-charts.newrelic.com',
  resource_name='newrelic-helm-repo',
  )

watch_all_namespaces = os.getenv('WATCH_ALL_NAMESPACES','true')

flags_helm = [
  # Each integration test runs on a different ephimeral namespace.
  '--set=flux2.watchAllNamespaces=' + watch_all_namespaces,
]

helm_resource(
  'flux',
  'newrelic/agent-control-cd',
  release_name='flux',
  # workaround for https://github.com/tilt-dev/tilt/issues/6058
  pod_readiness='ignore',
  update_dependencies=False,
  flags= flags_helm,
  resource_deps=['newrelic-helm-repo']
)

# build_with options:
# cargo: No crosscompilation, faster than cargo-zigbuild
# zig: Supports crosscompilaton
build_with = os.getenv('BUILD_WITH','zig')
arch = os.getenv('ARCH','arm64')
target_tuple = os.getenv('TARGET_TUPLE', 'aarch64-unknown-linux-musl')

#### Build SA binary

if build_with == 'cargo':
  local_resource(
      'build-binary',
      dir="../../../",
      cmd="cargo build --package newrelic_agent_control --bin newrelic-agent-control-k8s && mkdir -p bin && rm -f bin/newrelic-agent-control-"+arch+" && mv target/debug/newrelic-agent-control-k8s bin/newrelic-agent-control-"+arch,
      deps=["../../../agent-control/src"]
  )
elif build_with == 'zig':
  local_resource(
      'build-binary',
      dir="../../../",
      cmd="""cargo zigbuild --package newrelic_agent_control --bin newrelic-agent-control-k8s --target """+target_tuple+""" &&
        mkdir -p bin &&
        rm -f bin/newrelic-agent-control-"""+arch+""" &&
        mv target/"""+target_tuple+"""/debug/newrelic-agent-control-k8s bin/newrelic-agent-control-"""+arch,
      deps=[
        './agent-control',
      ]
  )

# Why not using docker_build: 
# Custom build shows injected values (first lines of log) which makes easy to understand what Tilt is using under the hood 
# as docker engine to compile or where is pushing the images depending on the registry auto-detection.
# Pushing a image to minikube in a way that is supported in different environments (mac, linux, different runners, etc) is tricky.
# If there is no exposed registry (no registry addon activated or ctptl registry) Tilt builds this image using eval method, and this
# is what is expected here.
custom_build(
  'tilt.local/ac-dev',
  # $EXPECTED_REF contains the defined name:tag 'tilt.local/ac-dev:dev'
  command='docker build -f Dockerfiles/Dockerfile_agent_control -t $EXPECTED_REF .',
  dir='../../../',
  tag='dev',
  deps=['build-binary']
)
# workaround to trigger the image build (Tilt expects at least one k8s resource using that image to trigger the build)
job_create(
  'build-image-trigger',
  image='tilt.local/ac-dev',
  command=['sh', '-c', 'exit'],
  resource_deps=['build-binary'],
)

#### install chart museum
helm_repo(
  'chartmuseum',
  'https://chartmuseum.github.io/charts',
  resource_name='chartmuseum-repo',
  )

helm_resource(
  'chartmuseum',
  'chartmuseum/chartmuseum',
  namespace='default',
  release_name='chartmuseum',
  resource_deps=['chartmuseum-repo'],
  # activate API to upload charts
  flags=['--set=env.open.DISABLE_API=false'],
  port_forwards=['8080']
)

#### build data/charts and upload it to chart museum
### Feature Branch Workaround ###
# Use the branch source to get the chart form a feature branch in the NR helm-charts repo.
feature_branch = 'master'

# We're modifying the default image in the charts for different versions because we don't expose the values to be
# modified by the remote_config but we do tests upgrading charts that require image modification
# in order to ensure the correct behavior.

# We are doing modifications to the checkout and pushing them after each modification to create the following versions:
# - 0.0.0-latest-released uses remote image
# - 0.0.1-dev and 0.0.2-dev the image tilt.local/ac-dev:dev
# - 0.0.0-crash use an image executing exit 1


local_resource(
    'clone-charts-repo',
    cmd="""rm -rf local/helm-charts-tmp && git clone --depth=1 https://github.com/newrelic/helm-charts --branch """ + feature_branch +"""  local/helm-charts-tmp""",
)

local_resource(
    'package-and-upload-ac-cd',
    cmd="""helm package --dependency-update --version "0.0.1-upstream" --destination local/helm-charts-tmp local/helm-charts-tmp/charts/agent-control-cd &&
     helm package --dependency-update --version "0.0.2-upstream" --destination local/helm-charts-tmp local/helm-charts-tmp/charts/agent-control-cd &&
     curl -X DELETE http://localhost:8080/api/charts/agent-control-cd/0.0.1-upstream &&
     curl -X DELETE http://localhost:8080/api/charts/agent-control-cd/0.0.2-upstream &&
     curl --data-binary "@local/helm-charts-tmp/agent-control-cd-0.0.1-upstream.tgz" http://localhost:8080/api/charts &&
     curl --data-binary "@local/helm-charts-tmp/agent-control-cd-0.0.2-upstream.tgz" http://localhost:8080/api/charts
    """,
    resource_deps=['chartmuseum','clone-charts-repo'],
)

local_resource(
    'package-and-upload-remote-image-chart',
    cmd="""helm package --dependency-update --version "0.0.0-latest-released" --destination local/helm-charts-tmp local/helm-charts-tmp/charts/agent-control-deployment &&
     curl -X DELETE http://localhost:8080/api/charts/agent-control-deployment/0.0.0-latest-released &&
     curl --data-binary "@local/helm-charts-tmp/agent-control-deployment-0.0.0-latest-released.tgz" http://localhost:8080/api/charts
    """,
    resource_deps=['package-and-upload-ac-cd'],
)

# We are modifying the default image to tilt.local/ac-dev:dev.
local_resource(
    'package-and-upload-local-image-chart',
    cmd="""yq eval ".image.repository = \\"tilt.local/ac-dev\\"" -i local/helm-charts-tmp/charts/agent-control-deployment/values.yaml &&
     yq eval ".image.tag = \\"dev\\"" -i local/helm-charts-tmp/charts/agent-control-deployment/values.yaml &&
     helm package --dependency-update --version "0.0.1-dev" --destination local/helm-charts-tmp local/helm-charts-tmp/charts/agent-control-deployment &&
     helm package --dependency-update --version "0.0.2-dev" --destination local/helm-charts-tmp local/helm-charts-tmp/charts/agent-control-deployment &&
     curl -X DELETE http://localhost:8080/api/charts/agent-control-deployment/0.0.1-dev &&
     curl -X DELETE http://localhost:8080/api/charts/agent-control-deployment/0.0.2-dev &&
     curl --data-binary "@local/helm-charts-tmp/agent-control-deployment-0.0.1-dev.tgz" http://localhost:8080/api/charts &&
     curl --data-binary "@local/helm-charts-tmp/agent-control-deployment-0.0.2-dev.tgz" http://localhost:8080/api/charts
    """,
    resource_deps=['package-and-upload-remote-image-chart'],
)

# We are Modifying the default image to alpine:latest with custom command and decorating
# the pod with the app label 'failing-pod' to be selected when doing the tests
local_resource(
    'package-and-upload-failing-image-chart',
    cmd="""yq eval ".image.repository = \\"alpine\\"" -i local/helm-charts-tmp/charts/agent-control-deployment/values.yaml &&
     yq eval ".image.tag = \\"latest\\"" -i local/helm-charts-tmp/charts/agent-control-deployment/values.yaml &&
     yq eval ".image.command = [\\"sh\\", \\"-c\\", \\"exit 1\\"]" -i local/helm-charts-tmp/charts/agent-control-deployment/values.yaml &&
     yq eval ".podLabels.app = \\"failing-pod\\"" -i local/helm-charts-tmp/charts/agent-control-deployment/values.yaml &&
     helm package --dependency-update --version "0.0.0-crash" --destination local/helm-charts-tmp local/helm-charts-tmp/charts/agent-control-deployment &&
     curl -X DELETE http://localhost:8080/api/charts/agent-control-deployment/0.0.0-crash &&
     curl --data-binary "@local/helm-charts-tmp/agent-control-deployment-0.0.0-crash.tgz" http://localhost:8080/api/charts
    """,
    resource_deps=['package-and-upload-local-image-chart'],
)

enable_vault = os.getenv('ENABLE_VAULT', 'false').lower() == 'true'

if enable_vault:
    ### We create a vault instance reachable at http://127.0.0.1:8200 with a kv1 engine secret with the values from
    ### data/vault_kv1_secrets.json and a kv2 engine secret with the values from vault_kv2_secrets.json, dev token is root
    helm_remote(
      'vault',
      repo_name='hashicorp',
      repo_url='https://helm.releases.hashicorp.com',
      set=['server.dev.enabled=true','server.serviceAccount.create=true']
    )

    # expose the service on localhost:8200
    k8s_resource(
      workload='vault',
      port_forwards=8200
    )

    local_resource(
        'enable_kv1',
        cmd="""curl --header "X-Vault-Token: root" --request POST --data '{"type":"kv","options":{"version":1}}' http://127.0.0.1:8200/v1/sys/mounts/kv-v1
        """,
        resource_deps=['vault'],
    )

    # kv2 is enabled by default
    local_resource(
        'populate_vault_v1_v2_secrets',
        cmd="""curl --header "X-Vault-Token: root" --request POST --data @data/vault_kv1_secrets.json http://127.0.0.1:8200/v1/kv-v1/my-secret &&
         curl --header "X-Vault-Token: root" --request POST --data @data/vault_kv2_secrets.json http://127.0.0.1:8200/v1/secret/data/my-secret
       """,
        resource_deps=['enable_kv1'],
    )
